model_list:
  # OpenAI Models
  - model_name: "gpt-3.5-turbo"
    litellm_params:
      model: "gpt-3.5-turbo"
      api_key: "os.environ/OPENAI_API_KEY"
      
  - model_name: "gpt-4"
    litellm_params:
      model: "gpt-4"
      api_key: "os.environ/OPENAI_API_KEY"
      
  - model_name: "gpt-4-turbo"
    litellm_params:
      model: "gpt-4-turbo"
      api_key: "os.environ/OPENAI_API_KEY"
      
  - model_name: "gpt-4o"
    litellm_params:
      model: "gpt-4o"
      api_key: "os.environ/OPENAI_API_KEY"

  # Anthropic Models
  - model_name: "claude-3-sonnet"
    litellm_params:
      model: "anthropic/claude-3-sonnet-20240229"
      api_key: "os.environ/ANTHROPIC_API_KEY"
      
  - model_name: "claude-3-opus"
    litellm_params:
      model: "anthropic/claude-3-opus-20240229"
      api_key: "os.environ/ANTHROPIC_API_KEY"
      
  - model_name: "claude-3-haiku"
    litellm_params:
      model: "anthropic/claude-3-haiku-20240307"
      api_key: "os.environ/ANTHROPIC_API_KEY"

  # Google Models
  - model_name: "gemini-pro"
    litellm_params:
      model: "gemini/gemini-pro"
      api_key: "os.environ/GOOGLE_API_KEY"
      
  - model_name: "gemini-pro-vision"
    litellm_params:
      model: "gemini/gemini-pro-vision"
      api_key: "os.environ/GOOGLE_API_KEY"

  # Azure OpenAI (uncomment and configure if using Azure)
  # - model_name: "azure-gpt-4"
  #   litellm_params:
  #     model: "azure/gpt-4"
  #     api_key: "os.environ/AZURE_API_KEY"
  #     api_base: "https://your-resource.openai.azure.com/"
  #     api_version: "2024-02-15-preview"

  # Cohere Models
  - model_name: "command-r"
    litellm_params:
      model: "cohere/command-r"
      api_key: "os.environ/COHERE_API_KEY"
      
  - model_name: "command-r-plus"
    litellm_params:
      model: "cohere/command-r-plus"
      api_key: "os.environ/COHERE_API_KEY"

  # VPS Ollama Models (running on production server)
  - model_name: "llama3.2-local"
    litellm_params:
      model: "ollama/llama3.2"
      api_base: "http://38.242.229.78:11434"
      
  - model_name: "llama3.2:1b"
    litellm_params:
      model: "ollama/llama3.2:1b"
      api_base: "http://38.242.229.78:11434"

# General settings
general_settings:
  completion_model: "gpt-3.5-turbo"  # default model for chat completions
  
# Router settings for load balancing
router_settings:
  routing_strategy: "least-busy"  # options: "simple-shuffle", "least-busy", "usage-based-routing"
  model_group_alias: # allows multiple models to serve traffic for a single model name
    gpt-3.5-turbo:
      - gpt-3.5-turbo
    claude-3:
      - claude-3-sonnet
      - claude-3-haiku
    gemini:
      - gemini-pro
    local:
      - llama3.2-local
      - llama3.2:1b

# Fallbacks - if a model fails, try these alternatives
litellm_settings:
  fallbacks: [
    {"gpt-4": ["gpt-4-turbo", "claude-3-opus"]},
    {"gpt-3.5-turbo": ["claude-3-haiku", "gemini-pro", "llama3.2-local"]},
    {"claude-3-sonnet": ["gpt-4", "gemini-pro"]},
    {"gemini-pro": ["gpt-3.5-turbo", "claude-3-haiku"]},
    {"llama3.2-local": ["llama3.2:1b", "gpt-3.5-turbo"]},
    {"llama3.2:1b": ["llama3.2-local", "claude-3-haiku"]}
  ]
  
  # Rate limiting
  rpm: 100  # requests per minute
  tpm: 100000  # tokens per minute
  
  # Caching
  cache: true
  cache_params:
    type: "redis"
    host: "localhost"
    port: 6379
    password: null
    
  # Success callbacks
  success_callback: ["langfuse"]  # for logging successful calls
  failure_callback: ["langfuse"]  # for logging failed calls
  
  # Model cost tracking
  model_cost_map:
    "gpt-3.5-turbo": {
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "openai",
      "mode": "chat"
    }
    "gpt-4": {
      "input_cost_per_token": 0.00003,
      "output_cost_per_token": 0.00006,
      "litellm_provider": "openai",
      "mode": "chat"
    }
    "claude-3-sonnet": {
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "anthropic",
      "mode": "chat"
    }

# Environment-specific settings
environment_variables:
  OPENAI_API_KEY: ${OPENAI_API_KEY}
  ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY}
  GOOGLE_API_KEY: ${GOOGLE_API_KEY}
  COHERE_API_KEY: ${COHERE_API_KEY}
  AZURE_API_KEY: ${AZURE_API_KEY}